{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load for Corteva Code Challenge\n",
    "## This code section is in response to problem #2 - Ingestion\n",
    "The ingestion of the data is being completed using Python 3.9 from a Jupyter Notebook.  This solution was chosen because it allows for documentation along side the code.  The code was created in the notebook using Microsoft Visual Studio Code.  This provided a linter and code formatting utilizing the Jupyter extension.\n",
    "\n",
    "Data is loaded from the flat files to the stage tables of the database.  Once data is processed in the final tables the stage data is deleted.  For a more robust solution an arvhive set of tables might might since.\n",
    "\n",
    "Duplicates are handled by leveraging MySQL unique key constraints and the ON DUPLICATE KEY clause that allows for a similar result to the MERGE used by other RDBMS frameworks.  \n",
    "\n",
    "Logging has been added using the Phython logging module and places the results into a log directory. See set requirements for details on setting up the directories to support this code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Section\n",
    "This section contains the imports used for the rest of the code base.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import os\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import logging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Section\n",
    "This secion setups the configuration for the database, logging, and configuration file.\n",
    "\n",
    "The username and password is retreive from the machines environment variables.  This is just one way to secure the private details.\n",
    "\n",
    "Next the configuration file is defined and the log directory read in.\n",
    "\n",
    "The database connection is defined using a combination of environment and configuration settings.\n",
    "\n",
    "Finally all the SQL statements are included in this section.  These are placed here so they are easily available for review, additions, or modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_user = os.getenv('DBUSER')\n",
    "db_pass = os.getenv('DBPASS')\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "config.read('corteva.ini')\n",
    "\n",
    "log_directory = config['DEFAULT']['log_directory'].strip(\"'\")\n",
    "logging.basicConfig(level=logging.DEBUG, filename=log_directory+'corteva.log', filemode='w', format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S')\n",
    "\n",
    " \n",
    "mydb = mysql.connector.connect(\n",
    " host=config['DATABASE']['host'],\n",
    " user=db_user,\n",
    " password=db_pass,\n",
    " database=config['DATABASE']['database'])\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "sql1 = (\"INSERT INTO CCC_STG_YIELD_DATA (YIELD_FILE_NAME, YEAR_OF_YIELD, YIELD_AMOUNT )\"\n",
    "        \"VALUES (%s, %s, %s)\")\n",
    "colName1 = ['year', 'amount']\n",
    "dataType1 ={'year': str,'amount': int}\n",
    "\n",
    "sql2 = (\"INSERT INTO CCC_STG_WEATHER_STATION_DATA (FILE_NAME, DATE_OF_WEATHER, MAX_DAILY_TEMP,\"\n",
    "        \" MIN_DAILY_TEMP, DAILY_PRECIPITATION) \"\n",
    "        \"VALUES (%s, %s, %s, %s, %s)\")\n",
    "colName2 = ['date', 'max_temp', 'min_temp','precip']\n",
    "dataType2 ={'date': str,'max_temp': int, 'min_temp': int, 'precip': int}\n",
    "\n",
    "sqlDimYear = (\"INSERT INTO CCC_DIM_YEAR(YEAR_KEY, THE_YEAR, YYYY) \"\n",
    "              \"(SELECT DISTINCT NULL, YEAR_OF_YIELD, YEAR_OF_YIELD FROM CCC_STG_YIELD_DATA yd) \"\n",
    "              \"ON DUPLICATE KEY UPDATE YEAR_KEY=YEAR_KEY\")\n",
    "\n",
    "sqlFactYld = (\"INSERT INTO CCC_FACT_CROP_YIELD(YEAR_KEY, CROP_YIELD_AMOUNT) \"\n",
    "              \"(SELECT yd.YEAR_KEY, sy.YIELD_AMOUNT \"\n",
    "              \"FROM CCC_DIM_YEAR yd \"\n",
    "              \"JOIN CCC_STG_YIELD_DATA sy ON sy.YEAR_OF_YIELD = yd.THE_YEAR) \"\n",
    "              \"ON DUPLICATE KEY UPDATE CROP_YIELD_AMOUNT = sy.YIELD_AMOUNT\")\n",
    "\n",
    "sqlStgYldDel = (\"DELETE FROM CCC_STG_YIELD_DATA\")\n",
    "\n",
    "sqlDimDate = (\"INSERT INTO CCC_DIM_DATE(DATE_KEY, THE_DATE, DAY_OF_YEAR, WEEK_OF_YEAR, THE_MONTH, MONTH_NAME, \"\n",
    "              \"THE_QUARTER, QUARTER_NAME, THE_YEAR, DATE_SORT) \"\n",
    "              \"(SELECT DISTINCT NULL, STR_TO_DATE(DATE_OF_WEATHER, '%Y%m%d'), DAYOFYEAR(STR_TO_DATE(DATE_OF_WEATHER, '%Y%m%d')),\"\n",
    "              \"WEEKOFYEAR(STR_TO_DATE(DATE_OF_WEATHER, '%Y%m%d')), MONTH(STR_TO_DATE(DATE_OF_WEATHER, '%Y%m%d')), \"\n",
    "              \"MONTHNAME(STR_TO_DATE(DATE_OF_WEATHER, '%Y%m%d')), QUARTER(STR_TO_DATE(DATE_OF_WEATHER, '%Y%m%d')), \"\n",
    "              \"CONCAT('Q', QUARTER(STR_TO_DATE(DATE_OF_WEATHER, '%Y%m%d'))), YEAR(STR_TO_DATE(DATE_OF_WEATHER, '%Y%m%d')), \"\n",
    "              \"DATE_OF_WEATHER FROM CCC_STG_WEATHER_STATION_DATA) ON DUPLICATE KEY UPDATE DATE_KEY=DATE_KEY\")\n",
    "\n",
    "sqlDimWeatherStation = (\"INSERT INTO CCC_DIM_WEATHER_STATION(WEATHER_STATION_KEY, WEATHER_STATION_CODE, WEATHER_STATION_NAME) \"\n",
    "                        \"(SELECT DISTINCT NULL, SUBSTR(FILE_NAME, 1,  LOCATE('.txt', FILE_NAME,1)-1),SUBSTR(FILE_NAME, 1,  LOCATE('.txt', FILE_NAME,1)-1)\"\n",
    "                        \"FROM CCC_STG_WEATHER_STATION_DATA) ON DUPLICATE KEY UPDATE WEATHER_STATION_KEY=WEATHER_STATION_KEY\")\n",
    "\n",
    "sqlFactWeather = (\"INSERT INTO CCC_FACT_WEATHER(DATE_KEY, WEATHER_STATION_KEY, MAX_DAILY_TEMP, MIN_DAILY_TEMP, DAILY_PRECIPITATION) \"\n",
    "                  \"(SELECT dd.DATE_KEY, wd.WEATHER_STATION_KEY, wsd.MAX_DAILY_TEMP, wsd.MIN_DAILY_TEMP, wsd.DAILY_PRECIPITATION \"\n",
    "                  \"FROM CCC_STG_WEATHER_STATION_DATA wsd \"\n",
    "                  \"JOIN CCC_DIM_DATE dd ON dd.THE_DATE = STR_TO_DATE(DATE_OF_WEATHER, '%Y%m%d') \"\n",
    "                  \"JOIN CCC_DIM_WEATHER_STATION wd ON wd.WEATHER_STATION_CODE = SUBSTR(FILE_NAME, 1,  LOCATE('.txt', FILE_NAME,1)-1)) \"\n",
    "                  \"ON DUPLICATE KEY UPDATE MAX_DAILY_TEMP = wsd.MAX_DAILY_TEMP, MIN_DAILY_TEMP = wsd.MIN_DAILY_TEMP, \"\n",
    "                  \"DAILY_PRECIPITATION = wsd.DAILY_PRECIPITATION\")\n",
    "\n",
    "sqlStgWeatherDel = (\"DELETE FROM CCC_STG_WEATHER_STATION_DATA\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "This sections contains the functions used to load data into the database tables.  They are called by the next section of code in the appropriate order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadYieldFileToDF(yd, yf):\n",
    "    logging.debug('loadYieldFileToDF start')\n",
    "    yf_df = pd.read_csv(yd+yf,sep='\\t', names=colName1, dtype=dataType1)\n",
    "    logging.debug('loadYieldFileToDF end')\n",
    "    return yf_df\n",
    "\n",
    "def loadYieldFileToStage(yd, yf):\n",
    "    cnt = 0\n",
    "    logging.debug('loadYieldFileToStage start')\n",
    "    yld_df = loadYieldFileToDF(yd, yf)\n",
    "    for index, row in yld_df.iterrows():\n",
    "        #print(row['amount'], row['year'])\n",
    "        val1 = (yf\n",
    "           , row['year']\n",
    "           , row['amount'])\n",
    "        mycursor.execute(sql1, val1)\n",
    "        cnt = cnt + mycursor.rowcount\n",
    "        mydb.commit()\n",
    "    logging.debug('loadYieldFileToStage data frame size:'+ str(yld_df.size))\n",
    "    logging.debug('loadYieldFileToStage rows inserted to table:'+ str(cnt))\n",
    "    logging.debug('loadYieldFileToStage start')\n",
    "\n",
    "    return\n",
    "\n",
    "def loadDimYearFromYield():\n",
    "    logging.debug('loadDimYearFromYield start')\n",
    "    mycursor.execute(sqlDimYear)\n",
    "    logging.debug('loadDimYearFromYield rows: '+ str(mycursor.rowcount))\n",
    "    mydb.commit()\n",
    "    logging.debug('loadDimYearFromYield start')\n",
    "    return\n",
    "\n",
    "def loadFactYield():\n",
    "    logging.debug('loadFactYield start')\n",
    "    mycursor.execute(sqlFactYld)\n",
    "    mydb.commit()\n",
    "    logging.debug('loadFactYield rows: '+ str(mycursor.rowcount))\n",
    "\n",
    "    mycursor.execute(sqlStgYldDel)\n",
    "    mydb.commit()\n",
    "    logging.debug('loadFactYield end')\n",
    "    \n",
    "    return    \n",
    "\n",
    "def loadWeatherFileToDF(wd, wf):\n",
    "    logging.debug('loadWeatherFileToDF start')\n",
    "    wx_df = pd.read_csv(wd+wf,sep='\\t', names=colName2, dtype=dataType2)\n",
    "    logging.debug('loadWeatherFileToDF end')\n",
    "    return wx_df\n",
    "\n",
    "def loadWeatherFileToStage(wd, wf):\n",
    "    cnt = 0\n",
    "    logging.debug('loadWeatherFileToStage start')\n",
    "    wx_df = loadWeatherFileToDF(wd, wf)\n",
    "    for index, row in wx_df.iterrows():\n",
    "        val2 = (wf\n",
    "            , row['date']\n",
    "            , row['max_temp']\n",
    "            , row['min_temp']\n",
    "            , row['precip'])\n",
    "    \n",
    "        mycursor.execute(sql2, val2)\n",
    "        cnt = cnt + mycursor.rowcount\n",
    "        mydb.commit()\n",
    "    logging.debug('loadWeatherFileToStage rows: '+ str(cnt))\n",
    "    logging.debug('loadWeatherFileToStage end')\n",
    "    return\n",
    "\n",
    "def loadDimDateFromWeather():\n",
    "    logging.debug('loadDimDateFromWeather start')\n",
    "    mycursor.execute(sqlDimDate)\n",
    "    logging.debug('loadDimDateFromWeather rows:' + str(mycursor.rowcount))\n",
    "    mydb.commit()\n",
    "    logging.debug('loadDimDateFromWeather end')\n",
    "    return\n",
    "\n",
    "def loadDimWeatherStation():\n",
    "    logging.debug('loadDimWeatherStation start')\n",
    "    mycursor.execute(sqlDimWeatherStation)\n",
    "    logging.debug('loadDimWeatherStation rows: '+ str(mycursor.rowcount))\n",
    "    mydb.commit()\n",
    "    logging.debug('loadDimWeatherStation end')\n",
    "    return\n",
    "\n",
    "def loadFactWeather():\n",
    "    logging.debug('loadFactWeather start')\n",
    "    mycursor.execute(sqlFactWeather)\n",
    "    logging.debug('loadFactWeather rows: '+ str(mycursor.rowcount))\n",
    "    mydb.commit()\n",
    "\n",
    "    mycursor.execute(sqlStgWeatherDel)\n",
    "    mydb.commit()\n",
    "    logging.debug('loadFactWeather end')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main section\n",
    "This is the main section of the code.  Here the folders where the files are input to (as defined in the configuration file) are looped through looking for appropriate named files.  In code is setup to look in specific foilders for a specific type of file.  File naming could also have been used, but for this challenge the folder was sufficient.\n",
    "\n",
    "### The flow is as follows:\n",
    "    1) load yield data file(s) into the stage table\n",
    "    2) Validate the the year dimension table contains all the years in the stage table.  Add any that are missing.\n",
    "    3) Load the yield fact table.  Utilize the logic and constriants to handle duplicates.  Update the detail data if the values change.\n",
    "\n",
    "    4) Load the weather station data into the stage table\n",
    "    5) Validate the date dimension table contains all the dates in the stage table.  Add any that are missing.\n",
    "    6) Validate the weather station dimension table contains all the weather stations based on the file names provided.  Add any that are missing.\n",
    "    7) Load the weather fact table.  Utilize the logic and constriants to handle duplicates.  Update the detail data if the values change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.debug('Data Ingestion Main start')\n",
    "\n",
    "yield_directory = config['DEFAULT']['yield_directory'].strip(\"'\")\n",
    "\n",
    "archive_directory = config['DEFAULT']['archive_directory'].strip(\"'\")\n",
    "\n",
    "ylddir = os.fsencode(yield_directory)\n",
    "    \n",
    "for file in os.listdir(ylddir):\n",
    "     filename = os.fsdecode(file)\n",
    "     if filename.endswith(\".txt\"): #or filename.endswith(\".csv\"): \n",
    "         #Load file to yield tables\n",
    "         loadYieldFileToStage(yield_directory, filename)\n",
    "         os.rename(yield_directory+filename, archive_directory+filename)\n",
    "         continue\n",
    "     else:\n",
    "         #Add comment to log file\n",
    "         continue\n",
    "\n",
    "loadDimYearFromYield()\n",
    "loadFactYield()\n",
    "\n",
    "weather_directory = config['DEFAULT']['weather_directory'].strip(\"'\")\n",
    "wtrdir = os.fsencode(weather_directory)\n",
    "    \n",
    "for file in os.listdir(wtrdir):\n",
    "     filename = os.fsdecode(file)\n",
    "     if filename.endswith(\".txt\") or filename.endswith(\".csv\"): \n",
    "         #Load file to weather tables\n",
    "         loadWeatherFileToStage(weather_directory, filename)\n",
    "         os.rename(weather_directory+filename, archive_directory+filename)\n",
    "         continue\n",
    "     else:\n",
    "         #Add comment to log file\n",
    "         continue\n",
    "\n",
    "loadDimDateFromWeather()\n",
    "loadDimWeatherStation()\n",
    "loadFactWeather()\n",
    "\n",
    "logging.debug('Data Ingestion Main end')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
